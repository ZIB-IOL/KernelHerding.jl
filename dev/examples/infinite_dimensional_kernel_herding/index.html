<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Kernel herding: Frank-Wolfe algorithms in an infinite-dimensional setting · KernelHerding.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://ZIB-IOL.github.io/KernelHerding.jl/examples/infinite_dimensional_kernel_herding/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">KernelHerding.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Examples</span><ul><li class="is-active"><a class="tocitem" href>Kernel herding: Frank-Wolfe algorithms in an infinite-dimensional setting</a><ul class="internal"><li><a class="tocitem" href="#Kernel-herding:-a-primer"><span>Kernel herding: a primer</span></a></li><li><a class="tocitem" href="#Infinite-dimensional-kernel-herding"><span>Infinite-dimensional kernel herding</span></a></li><li><a class="tocitem" href="#Conclusion"><span>Conclusion</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li></ul></li><li><a class="tocitem" href="../../reference/">API reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li class="is-active"><a href>Kernel herding: Frank-Wolfe algorithms in an infinite-dimensional setting</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Kernel herding: Frank-Wolfe algorithms in an infinite-dimensional setting</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/ZIB-IOL/KernelHerding.jl/blob/main/examples/infinite_dimensional_kernel_herding.jl" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><pre><code class="language-julia hljs">using FrankWolfe
using Plots
using LinearAlgebra
using Random

include(joinpath(dirname(pathof(FrankWolfe)), &quot;../examples/plot_utils.jl&quot;))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Main.check_gradients</code></pre><h1 id="Kernel-herding:-Frank-Wolfe-algorithms-in-an-infinite-dimensional-setting"><a class="docs-heading-anchor" href="#Kernel-herding:-Frank-Wolfe-algorithms-in-an-infinite-dimensional-setting">Kernel herding: Frank-Wolfe algorithms in an infinite-dimensional setting</a><a id="Kernel-herding:-Frank-Wolfe-algorithms-in-an-infinite-dimensional-setting-1"></a><a class="docs-heading-anchor-permalink" href="#Kernel-herding:-Frank-Wolfe-algorithms-in-an-infinite-dimensional-setting" title="Permalink"></a></h1><p>In this example, we illustrate how the Frank-Wolfe algorithm can be applied to infinite-dimensional kernel herding problems. First, we present a quick primer on kernel herding.</p><h2 id="Kernel-herding:-a-primer"><a class="docs-heading-anchor" href="#Kernel-herding:-a-primer">Kernel herding: a primer</a><a id="Kernel-herding:-a-primer-1"></a><a class="docs-heading-anchor-permalink" href="#Kernel-herding:-a-primer" title="Permalink"></a></h2><p>Kernel herding is known to be equivalent to solving a quadratic optimization problem in a Reproducing Kernel Hilbert Space (RKHS) with the Frank-Wolfe algorithm (<a href="https://icml.cc/2012/papers/683.pdf">Bach et al.</a>). Here, we explain kernel herding following the presentation of <a href="https://arxiv.org/pdf/2205.12838.pdf">Wirth et al.</a>.</p><p>Let <span>$\mathcal{Y} \subseteq \mathbb{R}$</span> be an observation space, <span>$\mathcal{H}$</span> a RKHS with inner product <span>$\langle \cdot, \cdot \rangle_\mathcal{H}$</span>, and <span>$\Phi \colon \mathcal{Y} \to \mathcal{H}$</span> a feature map such that any element <span>$x\in \mathcal{H}$</span> has an associated real function defined via</p><p class="math-container">\[x(y) = \langle x, \Phi(y)\rangle_\mathcal{H}\]</p><p>for <span>$y\in \mathcal{Y}$</span>. The feature map <span>$\Phi$</span> has an associated positive defininte kernel</p><p class="math-container">\[k \colon (y, z) \mapsto k(y, z) := \langle \Phi(y), \Phi(z) \rangle_\mathcal{H}\]</p><p>for <span>$y,z\in \mathcal{Y}$</span>. Here, the feasible region is the marginal polytope</p><p class="math-container">\[\mathcal{C} : = \text{conv}\left(\lbrace \Phi(y) \mid y \in \mathcal{Y} \rbrace\right) \subseteq \mathcal{H}.\]</p><p>We consider a probability distribution <span>$\rho(y)$</span> over <span>$\mathcal{Y}$</span> with associated mean element</p><p class="math-container">\[\mu(z) : = \mathbb{E}_{\rho(y)} \Phi(y)(z) = \int_{\mathcal{Y}} k(z, y) \rho(y) dy \in \mathcal{C},\]</p><p>where <span>$\mu \in \mathcal{C}$</span> due to the support of <span>$p(y)$</span> being in <span>$\mathcal{Y}$</span>. Then, kernel herding is equivalent to solving the minimization problem</p><p class="math-container">\[\min_{x\in \mathcal{C}} f(x), \qquad \qquad \text{(OPT-KH)}\]</p><p>where <span>$f(x) := \frac{1}{2} \left\|x - \mu \right\|_\mathcal{H}^2$</span>, with the Frank-Wolfe algorithm and open loop step-size rule <span>$\eta_t = \frac{1}{t + 1}$</span>. The well-definedness of kernel herding is guaranteed if there exists a constant <span>$R &gt; 0$</span> such that <span>$\|\Phi(y)\|_\mathcal{H} = R$</span> for all <span>$y\in \mathcal{Y}$</span>. In that case, all extreme points of <span>$\mathcal{C}$</span> are of the form <span>$\Phi(y)$</span> for <span>$y\in \mathcal{Y}$</span>. Thus, iterates constructed with the Frank-Wolfe algorithm are convex combinations of the form <span>$x_t = \sum_{i=1}^t w_i \Phi(y_i)$</span>, where <span>$w =(w_1, \ldots, w_t)^\intercal \in \mathbb{R}^t$</span> is a weight vector such that <span>$w_i \geq 0$</span> for all <span>$i \in \{1, \ldots, t\}$</span> and <span>$\sum_{i=1}^t w_i = 1$</span>. Observe that the iterate <span>$x_t$</span> is the mean element of the associated empirical distribution <span>$\tilde{\rho}_t(y)$</span> over <span>$\mathcal{Y}$</span>, that is,</p><p class="math-container">\[\tilde{\mu}_t(z) = \mathbb{E}_{\tilde{\rho}_t(y)}\Phi(y)(z) = \sum_{i=1}^tw_i \Phi(y_i)(z) = x_t(z).\]</p><p>Then, <a href="https://icml.cc/2012/papers/683.pdf">Bach et al.</a> showed that</p><p class="math-container">\[\sup_{x\in \mathcal{H}, \|x\|_\mathcal{H} = 1} \lvert \mathbb{E}_{\rho (y)} [x(y)] - \mathbb{E}_{\tilde{\rho}_t(y)} [x(y)] \rvert = \|\mu - \tilde{\mu}_t\|_\mathcal{H}.\]</p><p>Thus, with kernel herding, by finding a good bound on <span>$\|\mu - \tilde{\mu}_t\|_\mathcal{H}$</span>, we can bound the error when computing the expectation of <span>$x\in \mathcal{H}$</span> with <span>$\|x\|_\mathcal{H} = 1$</span>.</p><h2 id="Infinite-dimensional-kernel-herding"><a class="docs-heading-anchor" href="#Infinite-dimensional-kernel-herding">Infinite-dimensional kernel herding</a><a id="Infinite-dimensional-kernel-herding-1"></a><a class="docs-heading-anchor-permalink" href="#Infinite-dimensional-kernel-herding" title="Permalink"></a></h2><p>Now that we have introduced the general kernel herding setting, we focus on a specific kernel studied in Wahba and later in <a href="https://icml.cc/2012/papers/683.pdf">Bach et al.</a> and <a href="https://arxiv.org/pdf/2205.12838.pdf">Wirth et al.</a> that maps into a Hilbert space whose ambient dimension is infinite. Let <span>$\mathcal{Y} = [0, 1]$</span> and</p><p class="math-container">\[\mathcal{H}:= \left\lbrace x \colon [0, 1] \to \mathbb{R} \mid x(y) = \sum_{j = 1}^\infty (a_j \cos(2\pi j y) + b_j \sin(2 \pi j y)), x&#39;(y) \in L^2([0,1]), \text{ and } a_j,b_j\in\mathbb{R}\right\rbrace.\]</p><p>For <span>$w, x \in \mathcal{H}$</span>,</p><p class="math-container">\[\langle w, x \rangle_\mathcal{H} := \int_{[0,1]} w&#39;(y)x&#39;(y)dy\]</p><p>defines an inner product. Thus, <span>$(\mathcal{H}, \langle \cdot, \cdot \rangle_{\mathcal{H}})$</span> is a Hilbert space. <a href="https://arxiv.org/pdf/2205.12838.pdf">Wirth et al.</a> showed that <span>$\mathcal{H}$</span> is a Reproducing Kernel Hilbert Space (RKHS) with associated kernel</p><p class="math-container">\[k(y, z) = \frac{1}{2} B_2(| y - z |),\]</p><p>where <span>$y,z\in [0, 1]$</span> and <span>$B_2(y) = y^2 - y + \frac{1}{6}$</span> is the Bernoulli polynomial.</p><h3 id="Set-up"><a class="docs-heading-anchor" href="#Set-up">Set-up</a><a id="Set-up-1"></a><a class="docs-heading-anchor-permalink" href="#Set-up" title="Permalink"></a></h3><p>Below, we compare different Frank-Wolfe algorithms for kernel herding in the Hilbert space <span>$\mathcal{H}$</span>: the Frank-Wolfe algorithm with open loop step-size rule <span>$\eta_t = \frac{2}{t+2}$</span> (FW-OL), the Frank-Wolfe algorithm with short-step (FW-SS), and the Blended Pairwise Frank-Wolfe algorithm with short-step (BPFW-SS). We do not use line search because it is equivalent to short-step for the squared loss used in kernel herding.</p><p>The LMO in the here-presented kernel herding problem is implemented using exhaustive search over <span>$\mathcal{Y} = [0, 1]$</span>.</p><pre><code class="language- hljs">max_iterations = 2000
max_iterations_lmo = 1.5 * max_iterations
lmo = MarginalPolytopeWahba(max_iterations_lmo)</code></pre><h3 id="Uniform-distribution"><a class="docs-heading-anchor" href="#Uniform-distribution">Uniform distribution</a><a id="Uniform-distribution-1"></a><a class="docs-heading-anchor-permalink" href="#Uniform-distribution" title="Permalink"></a></h3><p>First, we consider the uniform distribution <span>$\rho = 1$</span>, which results in the mean element being zero, that is, <span>$\mu = 0$</span>.</p><pre><code class="language- hljs">mu = ZeroMeanElement()
iterate = KernelHerdingIterate([1.0], [0.0])
gradient = KernelHerdingGradient(iterate, mu)
f, grad = create_loss_function_gradient(mu)

FW_OL = FrankWolfe.frank_wolfe(f, grad, lmo, iterate, line_search=FrankWolfe.Agnostic(), verbose=true, gradient=gradient, memory_mode=FrankWolfe.OutplaceEmphasis(), max_iteration=max_iterations, trajectory=true)
FW_SS = FrankWolfe.frank_wolfe(f, grad, lmo, iterate, line_search=FrankWolfe.Shortstep(1), verbose=true, gradient=gradient, memory_mode=FrankWolfe.OutplaceEmphasis(), max_iteration=max_iterations, trajectory=true)
BPFW_SS = FrankWolfe.blended_pairwise_conditional_gradient(f, grad, lmo, iterate, line_search=FrankWolfe.Shortstep(1), verbose=true, gradient=gradient, memory_mode=FrankWolfe.OutplaceEmphasis(), max_iteration=max_iterations, trajectory=true)</code></pre><p>We plot the results.</p><pre><code class="language- hljs">data = [FW_OL[end], FW_SS[end], BPFW_SS[end - 1]]
labels = [&quot;FW-OL&quot;, &quot;FW-SS&quot;, &quot;BPFW-SS&quot;]
plot_trajectories(data, labels, xscalelog=true)</code></pre><p>Observe that FW-OL converges faster than FW-SS and BPFW-SS. <a href="https://arxiv.org/pdf/2205.12838.pdf">Wirth et al.</a> proved an accelerated convergence rate of <span>$\mathcal{O}(1/t^2)$</span> for FW-OL with step-size rule <span>$\eta_t = \frac{1}{t+1}$</span>, but it remains an open problem to prove that FW-SS and BPFW-SS do not admit this accelerated rate.</p><h3 id="Non-uniform-distribution"><a class="docs-heading-anchor" href="#Non-uniform-distribution">Non-uniform distribution</a><a id="Non-uniform-distribution-1"></a><a class="docs-heading-anchor-permalink" href="#Non-uniform-distribution" title="Permalink"></a></h3><p>Second, we consider a non-uniform distribution</p><p class="math-container">\[\rho(y) \backsim \left(\sum_{i = 1}^n a_i \cos(2\pi i y) + b_i \sin (2\pi i y) \right)^2,\]</p><p>where <span>$n\in \mathbb{N}$</span>, <span>$a_i,b_i \in \mathbb{R}$</span> for all <span>$i \in \{1, \ldots, n\}$</span>, and <span>$a_i, b_i$</span> are chosen such that</p><p class="math-container">\[\int_{\mathcal{Y}} \rho(y) dy = 1.\]</p><p>To obtain such a <span>$\rho$</span>, we start with an arbitrary tuple of vectors:</p><pre><code class="language-julia hljs">rho = (rand(Float64, (1, 5)), rand(Float64, (1, 8)))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">([0.6724224549157489 0.2817352894794387 … 0.8749051487271016 0.04997658263875793], [0.036333818659948 0.1770972675170399 … 0.7585111895938335 0.3760682170979619])</code></pre><p>We then normalize the vectors to obtain a <span>$\rho$</span> that is indeed a distribution.</p><pre><code class="language- hljs">normalized_rho = construct_rho(rho)</code></pre><p>We then run the experiments.</p><pre><code class="language- hljs">mu = mu_from_rho(normalized_rho)
iterate = KernelHerdingIterate([1.0], [0.0])
gradient = KernelHerdingGradient(iterate, mu)
f, grad = create_loss_function_gradient(mu)

FW_OL = FrankWolfe.frank_wolfe(f, grad, lmo, iterate, line_search=FrankWolfe.Agnostic(), verbose=true, gradient=gradient, memory_mode=FrankWolfe.OutplaceEmphasis(), max_iteration=max_iterations, trajectory=true)
FW_SS = FrankWolfe.frank_wolfe(f, grad, lmo, iterate, line_search=FrankWolfe.Shortstep(1), verbose=true, gradient=gradient, memory_mode=FrankWolfe.OutplaceEmphasis(), max_iteration=max_iterations, trajectory=true)
BPFW_SS = FrankWolfe.blended_pairwise_conditional_gradient(f, grad, lmo, iterate, line_search=FrankWolfe.Shortstep(1), verbose=true, gradient=gradient, memory_mode=FrankWolfe.OutplaceEmphasis(), max_iteration=max_iterations, trajectory=true)</code></pre><p>We plot the results.</p><pre><code class="language- hljs">data = [FW_OL[end], FW_SS[end], BPFW_SS[end - 1]]
labels = [&quot;FW-OL&quot;, &quot;FW-SS&quot;, &quot;BPFW-SS&quot;]
plot_trajectories(data, labels, xscalelog=true)</code></pre><p>Observe that FW-OL converges with a rate of <span>$\mathcal{O}(1/t^2)$</span>, which is faster than the <span>$\mathcal{O}(1/t)$</span> convergence rate of FW-SS and BPFW-SS. To the best of our knowledge, an explanation for this acceleration is yet to be given.</p><h2 id="Conclusion"><a class="docs-heading-anchor" href="#Conclusion">Conclusion</a><a id="Conclusion-1"></a><a class="docs-heading-anchor-permalink" href="#Conclusion" title="Permalink"></a></h2><p>We presented two experiments which show how to use Frank-Wolfe algorithms to solve optimization problems in infinite-dimensional Hilbert spaces.</p><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><p>Bach, F., Lacoste-Julien, S. and Obozinski, G., 2012, June. On the Equivalence between Herding and Conditional Gradient Algorithms. <a href="https://icml.cc/2012/papers/683.pdf">In ICML 2012 International Conference on Machine Learning.</a></p><p>Wahba, G., 1990. Spline models for observational data. Society for industrial and applied mathematics.</p><p>Wirth, E., Kerdreux, T. and Pokutta, S., 2022. Acceleration of Frank-Wolfe algorithms with open loop step-sizes. <a href="https://arxiv.org/pdf/2205.12838.pdf">arXiv preprint arXiv:2205.12838.</a></p><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../">« Home</a><a class="docs-footer-nextpage" href="../../reference/">API reference »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Thursday 23 February 2023 14:39">Thursday 23 February 2023</span>. Using Julia version 1.6.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
