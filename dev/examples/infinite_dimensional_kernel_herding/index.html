<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Kernel herding: The Frank-Wolfe algorithm in an infinite-dimensional setting · KernelHerding.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://ZIB-IOL.github.io/KernelHerding.jl/examples/infinite_dimensional_kernel_herding/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">KernelHerding.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Examples</span><ul><li class="is-active"><a class="tocitem" href>Kernel herding: The Frank-Wolfe algorithm in an infinite-dimensional setting</a><ul class="internal"><li><a class="tocitem" href="#Kernel-herding"><span>Kernel herding</span></a></li><li><a class="tocitem" href="#Infinite-dimensional-kernel-herding"><span>Infinite-dimensional kernel herding</span></a></li></ul></li></ul></li><li><span class="tocitem">API reference</span><ul><li><a class="tocitem" href="../../reference/ref/">-</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li class="is-active"><a href>Kernel herding: The Frank-Wolfe algorithm in an infinite-dimensional setting</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Kernel herding: The Frank-Wolfe algorithm in an infinite-dimensional setting</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/ZIB-IOL/KernelHerding.jl/blob/main/examples/infinite_dimensional_kernel_herding.jl" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><pre><code class="language- hljs">using FrankWolfe
using KernelHerding
using Plots
using LinearAlgebra
using Random

include(joinpath(dirname(pathof(FrankWolfe)), &quot;../examples/plot_utils.jl&quot;))</code></pre><h1 id="Kernel-herding:-The-Frank-Wolfe-algorithm-in-an-infinite-dimensional-setting"><a class="docs-heading-anchor" href="#Kernel-herding:-The-Frank-Wolfe-algorithm-in-an-infinite-dimensional-setting">Kernel herding: The Frank-Wolfe algorithm in an infinite-dimensional setting</a><a id="Kernel-herding:-The-Frank-Wolfe-algorithm-in-an-infinite-dimensional-setting-1"></a><a class="docs-heading-anchor-permalink" href="#Kernel-herding:-The-Frank-Wolfe-algorithm-in-an-infinite-dimensional-setting" title="Permalink"></a></h1><p>In this example, we illustrate how the Frank-Wolfe algorithm can be applied to infinite-dimensional kernel herding problems. We first introduce the general kernel herding setting before discussing the specifics of the example setting.</p><h2 id="Kernel-herding"><a class="docs-heading-anchor" href="#Kernel-herding">Kernel herding</a><a id="Kernel-herding-1"></a><a class="docs-heading-anchor-permalink" href="#Kernel-herding" title="Permalink"></a></h2><p>Kernel herding is known to be equivalent to solving a quadratic optimization problem in a Reproducing Kernel Hilbert Space (RKHS) with the Frank-Wolfe algorithm, as proved, e.g., in <a href="https://icml.cc/2012/papers/683.pdf">Bach et al.</a>. Here, we explain kernel herding following the presentation of <a href="https://arxiv.org/pdf/2205.12838.pdf">Wirth et al.</a>.</p><p>Let <span>$\mathcal{Y} \subseteq \mathbb{R}$</span> be an observation space, <span>$\mathcal{H}$</span> a RKHS with inner product <span>$\langle \cdot, \cdot \rangle_\mathcal{H}$</span>, and <span>$\Phi \colon \mathcal{Y} \to \mathcal{H}$</span> a feature map such that any element <span>$x\in \mathcal{H}$</span> has an associated real function defined via</p><p class="math-container">\[x(y) = \langle x, \Phi(y)\rangle_\mathcal{H}\]</p><p>for <span>$y\in \mathcal{Y}$</span>. The feasible region in kernel herding is usually the marginal polytope <span>$\mathcal{C}\subseteq \mathcal{H}$</span>, which is defined via</p><p class="math-container">\[\mathcal{C} : = \text{conv}\left(\lbrace \Phi(y) \mid y \in \mathcal{Y} \rbrace\right) \subseteq \mathcal{H}.\]</p><p>We consider a probability distribution <span>$\rho(y)$</span> over <span>$\mathcal{Y}$</span> with associated mean element</p><p class="math-container">\[\mu : = \mathbb{E}_{\rho(y)} \Phi(y)(z) = \int_{\mathcal{Y}} k(z, y) \rho(y) dy \in \mathcal{C},\]</p><p>where <span>$\mu in \mathcal{C}$</span> is guaranteed because the support of <span>$p(y)$</span> is in <span>$\mathcal{Y}$</span>. Then, kernel herding is equivalent to solving the minimization problem</p><p class="math-container">\[\min_{x\in \mathcal{C}} f(x), \qquad \qquad (OPT--KH)\]</p><p>where <span>$f(x) := \frac{1}{2} \left\|x - \mu \right\|_\mathcal{H}^2$</span>, with the Frank-Wolfe algorithm and open loop step-size rule <span>$\eta_t = \frac{1}{t + 1}$</span>. The well-definedness of kernel herding is guaranteed if there exists a constant <span>$R &gt; 0$</span> such that <span>$\|\Phi(y)\|_\mathcal{H} = R$</span> for all <span>$y\in \mathcal{Y}$</span>. Moreover, all extreme points of <span>$\mathcal{C}$</span> are of the form <span>$\Phi(y)$</span> for <span>$y\in \mathcal{Y}$</span>. Thus, iterates constructed with the Frank-Wolfe algorithm are convex combinations of the form <span>$x_t = \sum_{i=1}^t w_i \Phi(y_i)$</span>, where <span>$w =(w_1, \ldots, w_t)^\intercal \in \mathbb{R}^t$</span> is a weight vector such that <span>$w_i \geq 0$</span> for all <span>$i \in \{1, \ldots, t}$</span> and <span>$\sum_{i=1}^t w_i = 1$</span>. The iterate <span>$x_t$</span> is the mean element of the associated empirical distribution <span>$\tilde{p}_t(y)$</span> over <span>$\mathcal{Y}$</span>, that is,</p><p class="math-container">\[\tilde{\mu}_t(z) = \mathbb{E}_{\tilde{\rho}_t(y)}\Phi(y)(z) = \sum_{i=1}^tw_i \Phi(y_i)(z) = x_t(z).\]</p><p>Then,</p><p class="math-container">\[\sup_{x\in \mathcal{H}, \|x\|_\mathcal{H} = 1} \lvert \mathbb{E}_{\rho (y)} x(y) - \mathbb{E}_{\tilde{\rho}_t(y)} x(y) \rvert = \|\mu - \tilde{\mu}_t\|_\mathcal{H}.\]</p><p>Thus, with kernel herding, by finding a good bound on <span>$\|\mu - \tilde{\mu}_t\|_\mathcal{H}$</span>, we can bound the error when computing the expectation of <span>$x\in \mathcal{H}$</span> with <span>$\|x\|_\mathcal{H} = 1$</span>.</p><h2 id="Infinite-dimensional-kernel-herding"><a class="docs-heading-anchor" href="#Infinite-dimensional-kernel-herding">Infinite-dimensional kernel herding</a><a id="Infinite-dimensional-kernel-herding-1"></a><a class="docs-heading-anchor-permalink" href="#Infinite-dimensional-kernel-herding" title="Permalink"></a></h2><p>Now that we have introduced the general kernel herding setting, we focus on a specific kernel studied in <a href="https://icml.cc/2012/papers/683.pdf">Bach et al.</a> and <a href="https://arxiv.org/pdf/2205.12838.pdf">Wirth et al.</a>. Let <span>$\mathcal{Y} = [0, 1]$</span> and</p><p class="math-container">\[\mathcal{H}:= \left\lbrace x \colon [0, 1] \to \mathbb{R} \mid x(y) = \sum_{j = 1}^\infty (a_j \cos(2\pi j y) + b_j \sin(2 \pi j y)), x&#39;(y) \in L^2([0,1]), \text{ and } a_j,b_j\in\mathbb{R}\right\rbrace.\]</p><p>From now on, we will write <span>$[0, 1]$</span> instead of <span>$\mathcal{Y}$</span> to keep notation light. For <span>$w, x \in \mathcal{H}$</span>,</p><p class="math-container">\[\langle w, x \rangle_\mathcal{H} := \int_{[0,1]} w&#39;(y)x&#39;(y)dy\]</p><p>is an inner product. Thus, <span>$(\mathcal{H}, \langle \cdot, \cdot \rangle_{\mathcal{H}})$</span> is a Hilbert space. <a href="https://arxiv.org/pdf/2205.12838.pdf">Wirth et al.</a> showed that <span>$\mathcal{H}$</span> is a Reproducing Kernel Hilbert Space (RKHS) with associated kernel</p><p class="math-container">\[k(y, z) = \frac{1}{2} B_2(| y - z |),\]</p><p>where <span>$y,z\in [0, 1]$</span> and <span>$B_2(y) = y^2 - y + \frac{1}{6}$</span> is the Bernoulli polynomial.</p><h3 id="Set-up"><a class="docs-heading-anchor" href="#Set-up">Set-up</a><a id="Set-up-1"></a><a class="docs-heading-anchor-permalink" href="#Set-up" title="Permalink"></a></h3><p>Below, we compare different Frank-Wolfe algorithm versions for kernel herding in the Hilbert space <span>$\mathcal{H}$</span>. We always compare the Frank-Wolfe algorithm with open loop step-size rule <span>$\eta_t = \frac{1}{t+1}$</span> (FW-OL), Frank-Wolfe algorithm with short-step (FW-SS), and the Blended Pairwise Frank-Wolfe algorithm with short-step (BPFW-SS). We do not use line search because it is equivalent to the short-step for the squared loss used in kernel herding.</p><p>The LMO in the here-presented kernel herding problem is implemented using exhaustive search over <span>$\mathcal{Y} = [0, 1]$</span>, which we perform for twice the number of iterations we run the Frank-Wolfe algorithms for.</p><pre><code class="language-julia hljs">max_iterations = 1000
max_iterations_lmo = 2 * max_iterations
lmo = MarginalPolytopeWahba(max_iterations_lmo)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">MarginalPolytopeWahba(2000)</code></pre><h3 id="Uniform-distribution"><a class="docs-heading-anchor" href="#Uniform-distribution">Uniform distribution</a><a id="Uniform-distribution-1"></a><a class="docs-heading-anchor-permalink" href="#Uniform-distribution" title="Permalink"></a></h3><p>First, we consider the uniform distribution <span>$\rho = 1$</span>, which results in the mean element being zero, that is, <span>$\mu = 0$</span>.</p><pre><code class="language- hljs">mu = ZeroMeanElement()
iterate = KernelHerdingIterate([1.0], [0.0])
gradient = KernelHerdingGradient(iterate, mu)
f, grad = create_loss_function_gradient(mu)

FW_OL = FrankWolfe.frank_wolfe(f, grad, lmo, iterate, line_search=FrankWolfe.Agnostic(), verbose=true, gradient=gradient, memory_mode=FrankWolfe.OutplaceEmphasis(), max_iteration=max_iterations, trajectory=true)
FW_SS = FrankWolfe.frank_wolfe(f, grad, lmo, iterate, line_search=FrankWolfe.Shortstep(1), verbose=true, gradient=gradient, memory_mode=FrankWolfe.OutplaceEmphasis(), max_iteration=max_iterations, trajectory=true)
BPFW_SS = FrankWolfe.blended_pairwise_conditional_gradient(f, grad, lmo, iterate, line_search=FrankWolfe.Shortstep(1), verbose=true, gradient=gradient, memory_mode=FrankWolfe.OutplaceEmphasis(), max_iteration=max_iterations, trajectory=true)
data = [FW_OL[end], FW_SS[end], BPFW_SS[end - 1]]
labels = [&quot;FW-OL&quot;, &quot;FW-SS&quot;, &quot;BPFW-SS&quot;]
plot_trajectories(data, labels, xscalelog=true)</code></pre><p>Observe that FW-OL converges faster than FW-SS and BPFW-SS. <a href="https://arxiv.org/pdf/2205.12838.pdf">Wirth et al.</a> proved the accelerated convergence rate of <span>$\mathcal{O}(1/t^2)$</span> for FW-OL, but it remains an open problem to prove that FW-SS and BPFW-SS do not admit this accelerated rate.</p><h3 id="Non-uniform-distribution"><a class="docs-heading-anchor" href="#Non-uniform-distribution">Non-uniform distribution</a><a id="Non-uniform-distribution-1"></a><a class="docs-heading-anchor-permalink" href="#Non-uniform-distribution" title="Permalink"></a></h3><p>Second, we consider a non-uniform distribution</p><p class="math-container">\[\rho(y) \backsim \left(\sum_{i = 1}^n a_i \cos(2\pi i y) + b_i \sin (2\pi i y) \right)^2,\]</p><p>where <span>$n\in \mathbb{N}$</span>, <span>$a_i,b_i \in \mathbb{R}$</span> for all <span>$i \in \{1, \ldots, n}$</span>, and <span>$a_i, b_i$</span> are chosen such that</p><p class="math-container">\[\int_{\mathcal{Y}} \rho(y) dy = 1.\]</p><p>To obtain such a <span>$\rho$</span>, we start with an arbitrary tuple of vectors:</p><pre><code class="language-julia hljs">rho = (rand((1, 5)), rand((1, 8)))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(5, 1)</code></pre><p>We then normalize the vectors to obtain a <span>$\rho$</span> that is indeed a distribution.</p><pre><code class="language-julia hljs">normalized_rho = construct_rho(rho)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(1.386750490563073, 0.2773500981126146)</code></pre><p>We then run the experiments.</p><pre><code class="language- hljs">mu = mu_from_rho(normalized_rho)
iterate = KernelHerdingIterate([1.0], [0.0])
gradient = KernelHerdingGradient(iterate, mu)
f, grad = create_loss_function_gradient(mu)



FW_OL = FrankWolfe.frank_wolfe(f, grad, lmo, iterate, line_search=FrankWolfe.Agnostic(), verbose=true, gradient=gradient, memory_mode=FrankWolfe.OutplaceEmphasis(), max_iteration=max_iterations, trajectory=true)
FW_SS = FrankWolfe.frank_wolfe(f, grad, lmo, iterate, line_search=FrankWolfe.Shortstep(1), verbose=true, gradient=gradient, memory_mode=FrankWolfe.OutplaceEmphasis(), max_iteration=max_iterations, trajectory=true)
BPFW_SS = FrankWolfe.blended_pairwise_conditional_gradient(f, grad, lmo, iterate, line_search=FrankWolfe.Shortstep(1), verbose=true, gradient=gradient, memory_mode=FrankWolfe.OutplaceEmphasis(), max_iteration=max_iterations, trajectory=true)
data = [FW_OL[end], FW_SS[end], BPFW_SS[end - 1]]
labels = [&quot;FW-OL&quot;, &quot;FW-SS&quot;, &quot;BPFW-SS&quot;]
plot_trajectories(data, labels, xscalelog=true)</code></pre><p>Observe that FW-OL converges with a rate of <span>$\mathcal{O}(1/t^2)$</span>, which is faster than the convergence rate of <span>$\mathcal{O}(1/t)$</span> admitted by FW-SS and BPFW-SS. Explaining this phenomenon of acceleration remains an open problem.</p><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../">« Home</a><a class="docs-footer-nextpage" href="../../reference/ref/">- »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.21 on <span class="colophon-date" title="Thursday 14 July 2022 13:58">Thursday 14 July 2022</span>. Using Julia version 1.6.6.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
